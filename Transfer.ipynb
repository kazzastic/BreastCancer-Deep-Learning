{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazzastic/BreastCancer-Deep-Learning/blob/master/Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6kNQBtE3qRk",
        "colab_type": "code",
        "outputId": "71865869-4020-479f-9fe5-5e81ec859668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKuOROWumQBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNFtdGPuqS1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape = (227,227,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBrp3EpxqtJD",
        "colab_type": "code",
        "outputId": "e2f33faa-0981-43f3-cbc5-afab011c9db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "CLASSES = 2\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nCLASSES = 2\\nx = base_model.output\\nx = GlobalAveragePooling2D(name='avg_pool')(x)\\nx = Dropout(0.4)(x)\\npredictions = Dense(CLASSES, activation='softmax')(x)\\nmodel = Model(inputs=base_model.input, outputs=predictions)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nCLASSES = 2\\nx = base_model.output\\nx = GlobalAveragePooling2D(name='avg_pool')(x)\\nx = Dropout(0.4)(x)\\npredictions = Dense(CLASSES, activation='softmax')(x)\\nmodel = Model(inputs=base_model.input, outputs=predictions)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inoWZ5QKo-hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siB0dzMdm4xV",
        "colab_type": "code",
        "outputId": "e53ceea6-555c-4674-82d2-e0477023fd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "add_model = Sequential()\n",
        "add_model.add(base_model)\n",
        "add_model.add(Conv2D(96, kernel_size=5, strides=1))\n",
        "add_model.add(Activation('relu'))\n",
        "\n",
        "add_model.add(Conv2D(256, kernel_size=3, strides=1))\n",
        "add_model.add(Activation('relu'))\n",
        "\n",
        "#add_model.add(Conv2D(96, kernel_size=3, strides=1))\n",
        "#add_model.add(Activation('relu'))\n",
        "\n",
        "#add_model.add(GlobalAveragePooling2D())\n",
        "#add_model.add(Dropout(0.5))\n",
        "add_model.add(Flatten())\n",
        "add_model.add(Dense(2))\n",
        "add_model.add(Activation('sigmoid'))\n",
        "\n",
        "\n",
        "model = add_model\n",
        "kazim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=kazim,\n",
        "              metrics=['accuracy'],\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc4OJdqcAYlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idd3COtRpbHr",
        "colab_type": "code",
        "outputId": "4051e5b3-7bae-4ea7-b92c-b4d1c3025362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 3, 3, 96)          1228896   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 3, 3, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1, 1, 256)         221440    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 514       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 16,165,538\n",
            "Trainable params: 1,450,850\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 96)          1228896   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3, 3, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 256)         221440    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 16,165,538\n",
            "Trainable params: 1,450,850\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQrTsupkBzPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = '/content/drive/My Drive/Augmented '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ybBphsEL-X",
        "colab_type": "code",
        "outputId": "7512b584-deea-4b13-bce7-766baca2ac8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Pixel values rescaling from [0, 255] to [0, 1] interval\n",
        "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
        "batch_size = 32\n",
        "img_width, img_height = 227, 227\n",
        "# Retrieve images and their classes for train and validation sets\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'training')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'validation')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7716 images belonging to 2 classes.\n",
            "Found 1929 images belonging to 2 classes.\n",
            "Found 7716 images belonging to 2 classes.\n",
            "Found 1929 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwTONdlaGaob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "train_samples = 7716\n",
        "validation_samples = 1929"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8E2daORFgW0",
        "colab_type": "code",
        "outputId": "b479600e-479b-403c-a3d9-a49969d18fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# Model saving callback\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='Breast.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=32,\n",
        "        epochs=epochs,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps = 32,\n",
        "        callbacks=[checkpointer, early_stopping],\n",
        "        verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "31/32 [============================>.] - ETA: 28s - loss: 0.6910 - acc: 0.5726Epoch 1/100\n",
            "32/32 [==============================] - 966s 30s/step - loss: 0.6109 - acc: 0.6738\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67383, saving model to Breast.h5\n",
            "32/32 [==============================] - 1885s 59s/step - loss: 0.6891 - acc: 0.5742 - val_loss: 0.6109 - val_acc: 0.6738\n",
            "Epoch 2/100\n",
            "31/32 [============================>.] - ETA: 19s - loss: 0.6189 - acc: 0.6648Epoch 1/100\n",
            "32/32 [==============================] - 517s 16s/step - loss: 0.6172 - acc: 0.6631\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.67383\n",
            "32/32 [==============================] - 1136s 36s/step - loss: 0.6194 - acc: 0.6621 - val_loss: 0.6172 - val_acc: 0.6631\n",
            "Epoch 3/100\n",
            "31/32 [============================>.] - ETA: 18s - loss: 0.6302 - acc: 0.6406Epoch 1/100\n",
            "32/32 [==============================] - 502s 16s/step - loss: 0.5950 - acc: 0.6719\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67383\n",
            "32/32 [==============================] - 1101s 34s/step - loss: 0.6269 - acc: 0.6436 - val_loss: 0.5950 - val_acc: 0.6719\n",
            "Epoch 4/100\n",
            "31/32 [============================>.] - ETA: 19s - loss: 0.6159 - acc: 0.6598Epoch 1/100\n",
            "32/32 [==============================] - 517s 16s/step - loss: 0.5788 - acc: 0.7017\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.67383 to 0.70166, saving model to Breast.h5\n",
            "32/32 [==============================] - 1141s 36s/step - loss: 0.6128 - acc: 0.6655 - val_loss: 0.5788 - val_acc: 0.7017\n",
            "Epoch 5/100\n",
            "31/32 [============================>.] - ETA: 20s - loss: 0.5957 - acc: 0.6784Epoch 1/100\n",
            "32/32 [==============================] - 501s 16s/step - loss: 0.5826 - acc: 0.6963\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.70166\n",
            "32/32 [==============================] - 1159s 36s/step - loss: 0.5976 - acc: 0.6743 - val_loss: 0.5826 - val_acc: 0.6963\n",
            "Epoch 6/100\n",
            "31/32 [============================>.] - ETA: 19s - loss: 0.5804 - acc: 0.7075Epoch 1/100\n",
            "32/32 [==============================] - 513s 16s/step - loss: 0.5585 - acc: 0.7212\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.70166 to 0.72119, saving model to Breast.h5\n",
            "32/32 [==============================] - 1140s 36s/step - loss: 0.5886 - acc: 0.6988 - val_loss: 0.5585 - val_acc: 0.7212\n",
            "Epoch 7/100\n",
            "31/32 [============================>.] - ETA: 20s - loss: 0.5634 - acc: 0.7188Epoch 1/100\n",
            "32/32 [==============================] - 517s 16s/step - loss: 0.5531 - acc: 0.7397\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.72119 to 0.73975, saving model to Breast.h5\n",
            "32/32 [==============================] - 1196s 37s/step - loss: 0.5628 - acc: 0.7168 - val_loss: 0.5531 - val_acc: 0.7397\n",
            "Epoch 8/100\n",
            "31/32 [============================>.] - ETA: 12s - loss: 0.5416 - acc: 0.7308Epoch 1/100\n",
            "32/32 [==============================] - 505s 16s/step - loss: 0.5214 - acc: 0.7471\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.73975 to 0.74707, saving model to Breast.h5\n",
            "32/32 [==============================] - 917s 29s/step - loss: 0.5392 - acc: 0.7310 - val_loss: 0.5214 - val_acc: 0.7471\n",
            "Epoch 9/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5376 - acc: 0.7424 Epoch 1/100\n",
            "32/32 [==============================] - 490s 15s/step - loss: 0.5171 - acc: 0.7524\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.74707 to 0.75244, saving model to Breast.h5\n",
            "32/32 [==============================] - 774s 24s/step - loss: 0.5420 - acc: 0.7378 - val_loss: 0.5171 - val_acc: 0.7524\n",
            "Epoch 10/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5755 - acc: 0.7193 Epoch 1/100\n",
            "32/32 [==============================] - 464s 14s/step - loss: 0.5196 - acc: 0.7466\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75244\n",
            "32/32 [==============================] - 732s 23s/step - loss: 0.5728 - acc: 0.7202 - val_loss: 0.5196 - val_acc: 0.7466\n",
            "Epoch 11/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5307 - acc: 0.7334 Epoch 1/100\n",
            "32/32 [==============================] - 487s 15s/step - loss: 0.5216 - acc: 0.7402\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.75244\n",
            "32/32 [==============================] - 758s 24s/step - loss: 0.5319 - acc: 0.7349 - val_loss: 0.5216 - val_acc: 0.7402\n",
            "Epoch 12/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5622 - acc: 0.7218 Epoch 1/100\n",
            "32/32 [==============================] - 492s 15s/step - loss: 0.5188 - acc: 0.7358\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.75244\n",
            "32/32 [==============================] - 767s 24s/step - loss: 0.5611 - acc: 0.7217 - val_loss: 0.5188 - val_acc: 0.7358\n",
            "Epoch 13/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5185 - acc: 0.7409 Epoch 1/100\n",
            "32/32 [==============================] - 489s 15s/step - loss: 0.5130 - acc: 0.7617\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.75244 to 0.76172, saving model to Breast.h5\n",
            "32/32 [==============================] - 764s 24s/step - loss: 0.5208 - acc: 0.7388 - val_loss: 0.5130 - val_acc: 0.7617\n",
            "Epoch 14/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5414 - acc: 0.7248 Epoch 1/100\n",
            "32/32 [==============================] - 492s 15s/step - loss: 0.5091 - acc: 0.7549\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.76172\n",
            "32/32 [==============================] - 766s 24s/step - loss: 0.5451 - acc: 0.7227 - val_loss: 0.5091 - val_acc: 0.7549\n",
            "Epoch 15/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5306 - acc: 0.7365 Epoch 1/100\n",
            "32/32 [==============================] - 434s 14s/step - loss: 0.5149 - acc: 0.7510\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.76172\n",
            "32/32 [==============================] - 702s 22s/step - loss: 0.5285 - acc: 0.7395 - val_loss: 0.5149 - val_acc: 0.7510\n",
            "Epoch 16/100\n",
            "31/32 [============================>.] - ETA: 11s - loss: 0.4812 - acc: 0.7752Epoch 1/100\n",
            "32/32 [==============================] - 486s 15s/step - loss: 0.5027 - acc: 0.7622\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.76172 to 0.76221, saving model to Breast.h5\n",
            "32/32 [==============================] - 855s 27s/step - loss: 0.4804 - acc: 0.7769 - val_loss: 0.5027 - val_acc: 0.7622\n",
            "Epoch 17/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.4775 - acc: 0.7661 Epoch 1/100\n",
            "32/32 [==============================] - 486s 15s/step - loss: 0.5242 - acc: 0.7422\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.76221\n",
            "32/32 [==============================] - 761s 24s/step - loss: 0.4791 - acc: 0.7661 - val_loss: 0.5242 - val_acc: 0.7422\n",
            "Epoch 18/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.4856 - acc: 0.7646 Epoch 1/100\n",
            "32/32 [==============================] - 491s 15s/step - loss: 0.5779 - acc: 0.7305\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.76221\n",
            "32/32 [==============================] - 766s 24s/step - loss: 0.4973 - acc: 0.7588 - val_loss: 0.5779 - val_acc: 0.7305\n",
            "Epoch 19/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.4812 - acc: 0.7823 Epoch 1/100\n",
            "32/32 [==============================] - 487s 15s/step - loss: 0.5425 - acc: 0.7490\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.76221\n",
            "32/32 [==============================] - 767s 24s/step - loss: 0.4777 - acc: 0.7852 - val_loss: 0.5425 - val_acc: 0.7490\n",
            "Epoch 20/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5094 - acc: 0.7379 Epoch 1/100\n",
            "32/32 [==============================] - 490s 15s/step - loss: 0.5178 - acc: 0.7471\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.76221\n",
            "32/32 [==============================] - 766s 24s/step - loss: 0.5079 - acc: 0.7402 - val_loss: 0.5178 - val_acc: 0.7471\n",
            "Epoch 21/100\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5127 - acc: 0.7555 Epoch 1/100\n",
            "32/32 [==============================] - 482s 15s/step - loss: 0.5047 - acc: 0.7520\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.76221\n",
            "32/32 [==============================] - 757s 24s/step - loss: 0.5103 - acc: 0.7573 - val_loss: 0.5047 - val_acc: 0.7520\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUdHs68gHeOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}