{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazzastic/BreastCancer-Deep-Learning/blob/master/Breast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osVHXS1spYUm",
        "colab_type": "code",
        "outputId": "72b95650-273c-4770-bf78-6cd17291c991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXpyp2LcpaW5",
        "colab_type": "code",
        "outputId": "69d00cc1-5082-469a-f6e1-ed3a9488f234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuFvV40lpkAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = '/content/drive/My Drive/Augmented '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TfNlRD7pwBX",
        "colab_type": "code",
        "outputId": "8e663b58-f7b9-41c3-95f7-ac6545c9b736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Pixel values rescaling from [0, 255] to [0, 1] interval\n",
        "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
        "batch_size = 32\n",
        "img_width, img_height = 227, 227\n",
        "# Retrieve images and their classes for train and validation sets\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'training')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'validation')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7716 images belonging to 2 classes.\n",
            "Found 1929 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqGoinzVwTBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "train_samples = 7716\n",
        "validation_samples = 1929"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKTjgyDcru6u",
        "colab_type": "code",
        "outputId": "5456407f-5ae6-41a9-c40a-5063201bea56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "import time\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (5, 5), input_shape=(227,227,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "model.add(Conv2D(384, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(384, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=3))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(2048, activation = 'relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "Adam = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam,\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 223, 223, 96)      7296      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 223, 223, 96)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 111, 111, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 109, 109, 256)     221440    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 109, 109, 256)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 54, 54, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 52, 52, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 52, 52, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 50, 50, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 50, 50, 384)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 384)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 98304)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               25166080  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2048)              526336    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 4098      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 28,137,858\n",
            "Trainable params: 28,137,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzM_WkHDwYAl",
        "colab_type": "code",
        "outputId": "8ba72679-2efd-4341-a7d1-0b1139e7aee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# Model saving callback\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='Breast.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=32,\n",
        "        epochs=epochs,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps = 32,\n",
        "        callbacks=[checkpointer, early_stopping],\n",
        "        verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31/32 [============================>.] - ETA: 29s - loss: 0.6844 - acc: 0.5333Epoch 1/20\n",
            "32/32 [==============================] - 1041s 33s/step - loss: 0.6708 - acc: 0.6094\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.60938, saving model to Breast.h5\n",
            "32/32 [==============================] - 1992s 62s/step - loss: 0.6835 - acc: 0.5400 - val_loss: 0.6708 - val_acc: 0.6094\n",
            "Epoch 2/20\n",
            "31/32 [============================>.] - ETA: 20s - loss: 0.6585 - acc: 0.6381Epoch 1/20\n",
            "32/32 [==============================] - 461s 14s/step - loss: 0.6357 - acc: 0.6836\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.60938 to 0.68359, saving model to Breast.h5\n",
            "32/32 [==============================] - 1127s 35s/step - loss: 0.6581 - acc: 0.6416 - val_loss: 0.6357 - val_acc: 0.6836\n",
            "Epoch 3/20\n",
            "31/32 [============================>.] - ETA: 22s - loss: 0.6097 - acc: 0.6905Epoch 1/20\n",
            "32/32 [==============================] - 453s 14s/step - loss: 0.6357 - acc: 0.6846\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.68359 to 0.68457, saving model to Breast.h5\n",
            "32/32 [==============================] - 1149s 36s/step - loss: 0.6103 - acc: 0.6904 - val_loss: 0.6357 - val_acc: 0.6846\n",
            "Epoch 4/20\n",
            "31/32 [============================>.] - ETA: 19s - loss: 0.5908 - acc: 0.6950Epoch 1/20\n",
            "32/32 [==============================] - 473s 15s/step - loss: 0.5982 - acc: 0.7139\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.68457 to 0.71387, saving model to Breast.h5\n",
            "32/32 [==============================] - 1123s 35s/step - loss: 0.5886 - acc: 0.6968 - val_loss: 0.5982 - val_acc: 0.7139\n",
            "Epoch 5/20\n",
            "31/32 [============================>.] - ETA: 20s - loss: 0.5908 - acc: 0.7016Epoch 1/20\n",
            "32/32 [==============================] - 464s 15s/step - loss: 0.5803 - acc: 0.7080\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.71387\n",
            "32/32 [==============================] - 1128s 35s/step - loss: 0.5888 - acc: 0.7041 - val_loss: 0.5803 - val_acc: 0.7080\n",
            "Epoch 6/20\n",
            "31/32 [============================>.] - ETA: 20s - loss: 0.5763 - acc: 0.7056Epoch 1/20\n",
            "32/32 [==============================] - 473s 15s/step - loss: 0.5753 - acc: 0.7109\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.71387\n",
            "32/32 [==============================] - 1156s 36s/step - loss: 0.5799 - acc: 0.7002 - val_loss: 0.5753 - val_acc: 0.7109\n",
            "Epoch 7/20\n",
            "31/32 [============================>.] - ETA: 21s - loss: 0.5550 - acc: 0.7188Epoch 1/20\n",
            "32/32 [==============================] - 468s 15s/step - loss: 0.5786 - acc: 0.7246\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.71387 to 0.72461, saving model to Breast.h5\n",
            "32/32 [==============================] - 1169s 37s/step - loss: 0.5560 - acc: 0.7207 - val_loss: 0.5786 - val_acc: 0.7246\n",
            "Epoch 8/20\n",
            "31/32 [============================>.] - ETA: 11s - loss: 0.5831 - acc: 0.6885Epoch 1/20\n",
            "32/32 [==============================] - 443s 14s/step - loss: 0.5755 - acc: 0.7129\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.72461\n",
            "32/32 [==============================] - 819s 26s/step - loss: 0.5819 - acc: 0.6904 - val_loss: 0.5755 - val_acc: 0.7129\n",
            "Epoch 9/20\n",
            "31/32 [============================>.] - ETA: 7s - loss: 0.5667 - acc: 0.7006 Epoch 1/20\n",
            "32/32 [==============================] - 462s 14s/step - loss: 0.5738 - acc: 0.7246\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.72461\n",
            "32/32 [==============================] - 719s 22s/step - loss: 0.5671 - acc: 0.7021 - val_loss: 0.5738 - val_acc: 0.7246\n",
            "Epoch 10/20\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5446 - acc: 0.7349 Epoch 1/20\n",
            "32/32 [==============================] - 489s 15s/step - loss: 0.5772 - acc: 0.7168\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.72461\n",
            "32/32 [==============================] - 765s 24s/step - loss: 0.5419 - acc: 0.7373 - val_loss: 0.5772 - val_acc: 0.7168\n",
            "Epoch 11/20\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5529 - acc: 0.7218 Epoch 1/20\n",
            "32/32 [==============================] - 493s 15s/step - loss: 0.5635 - acc: 0.7139\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.72461\n",
            "32/32 [==============================] - 766s 24s/step - loss: 0.5502 - acc: 0.7246 - val_loss: 0.5635 - val_acc: 0.7139\n",
            "Epoch 12/20\n",
            "31/32 [============================>.] - ETA: 8s - loss: 0.5418 - acc: 0.7198 Epoch 1/20\n",
            "32/32 [==============================] - 465s 15s/step - loss: 0.5899 - acc: 0.7012\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.72461\n",
            "32/32 [==============================] - 738s 23s/step - loss: 0.5414 - acc: 0.7217 - val_loss: 0.5899 - val_acc: 0.7012\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2P1CM9uwfhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Breast.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU5qzgNg1jfe",
        "colab_type": "code",
        "outputId": "7fe8bb51-be2f-4371-d812-723bee66fa2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import math\n",
        "#from google.colab.patches import cv2_imshow\n",
        "\n",
        "CATEGORIES = [\"cancer\", \"normal\"]\n",
        "\n",
        "\n",
        "def prepare(filepath):\n",
        "    #IMG_SIZE = 220 # 50 in txt-based\n",
        "    img_array = cv2.imread(filepath)\n",
        "    new_array = cv2.resize(img_array, (736,459))\n",
        "\n",
        "    return new_array.reshape(-1, 736,459, 3)\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model(\"Breast.h5\")\n",
        "\n",
        "prediction = model.predict([prepare('/content/drive/My Drive/dataset/NORMAL/normal_04-A_0475_1.LEFT_MLO.LJPEG.1.jpg')])\n",
        "pred_percent = math.floor(prediction[0][0]*100)\n",
        "print(pred_percent,\"%\")\n",
        "print(prediction)  # will be a list in a list.\n",
        "print(CATEGORIES[int(prediction[0][0])])\n",
        "'''\n",
        "if(prediction[0][0]>prediction[0][1]):\n",
        "  result = prediction[0][0]\n",
        "else:\n",
        "  result = prediction[0][1]\n",
        "\n",
        "print(prediction)\n",
        "print(result*100)\n",
        "print(CATEGORIES[int(result)])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f7e555541524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Breast.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/dataset/NORMAL/normal_04-A_0475_1.LEFT_MLO.LJPEG.1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mpred_percent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_percent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f7e555541524>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#IMG_SIZE = 220 # 50 in txt-based\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnew_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m736\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m459\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m736\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m459\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH-M6nUM9RA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal = 2342\n",
        "cancer = 2367\n",
        "\n",
        "if(prediction[0][0]>prediction[0][1]):\n",
        "  result = prediction[0][0]\n",
        "else:\n",
        "  result = prediction[0][1]\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7H_nYYFFoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pixel values rescaling from [0, 255] to [0, 1] interval\n",
        "datagen1 = ImageDataGenerator(rescale=1. / 255)\n",
        "batch_size = 32\n",
        "train_data_dir1 = '/content/drive/My Drive/dataset1/' \n",
        "# Retrieve images and their classes for train and validation sets\n",
        "train_generator1 = datagen1.flow_from_directory(\n",
        "        train_data_dir1,\n",
        "        target_size=(224, 224),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSmIDauXFK6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "image_list = []\n",
        "i = 0\n",
        "for filename in glob.glob('/content/drive/My Drive/dataset/NORMAL/*.jpg'): #assuming jpg\n",
        "    im=filename\n",
        "    image_list.append(im)\n",
        "    #print(i)\n",
        "    i +=1\n",
        "len(image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvxQKWMVLVpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "j=0\n",
        "for i in range(len(image_list)):\n",
        "  temp = image_list[i]\n",
        "  im = Image.open(temp)\n",
        "  temp = temp.replace(\"jpg\", \"png\")\n",
        "  temp = temp.replace(\"/content/drive/My Drive/dataset/NORMAL/\", \"\")\n",
        "  temp = \"/content/drive/My Drive/PNG/normal/\"+temp\n",
        "  im.save(temp)\n",
        "  print(j)\n",
        "  j=j+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxyRRtu6DqBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoX_I6BZXSPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = image_list[0]\n",
        "temp = temp.replace(\"jpg\", \"png\")\n",
        "temp = temp.replace(\"/content/drive/My Drive/dataset/CANCER/\", \"\")\n",
        "temp = \"/content/drive/My Drive/PNG/cancer/\"+temp\n",
        "temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZHR8JJ2ZPKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}