{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "osVHXS1spYUm",
        "colab_type": "code",
        "outputId": "93e9d477-9c29-4849-9fa2-a4097f2667a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXpyp2LcpaW5",
        "colab_type": "code",
        "outputId": "bd15d26a-bcc4-4775-9a45-8ca2e22f98c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuFvV40lpkAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = '/content/drive/My Drive/Augmented '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TfNlRD7pwBX",
        "colab_type": "code",
        "outputId": "c84d7948-efe2-4524-cc08-9fd97112fe05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Pixel values rescaling from [0, 255] to [0, 1] interval\n",
        "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
        "batch_size = 32\n",
        "img_width, img_height = 227, 227\n",
        "# Retrieve images and their classes for train and validation sets\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'training',\n",
        "        color_mode='grayscale')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'validation',\n",
        "        color_mode='grayscale')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7716 images belonging to 2 classes.\n",
            "Found 1929 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqGoinzVwTBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "train_samples = 7716\n",
        "validation_samples = 1929"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKTjgyDcru6u",
        "colab_type": "code",
        "outputId": "cdb6fcb4-1619-4369-a64c-07209dec391b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "import time\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (5, 5), input_shape=(227,227,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "model.add(Conv2D(384, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(384, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=3))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(2048, activation = 'relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "Adam = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam,\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 223, 223, 96)      2496      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 223, 223, 96)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 109, 109, 256)     221440    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 109, 109, 256)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 52, 52, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 52, 52, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 50, 50, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 50, 50, 384)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 384)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 98304)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               25166080  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2048)              526336    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 4098      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 28,133,058\n",
            "Trainable params: 28,133,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzM_WkHDwYAl",
        "colab_type": "code",
        "outputId": "0cf53fc5-8777-4daf-cfcb-d592f9c927af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# Model saving callback\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='Breast.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=32,\n",
        "        epochs=epochs,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps = 32,\n",
        "        callbacks=[checkpointer, early_stopping],\n",
        "        verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "31/32 [============================>.] - ETA: 26s - loss: 0.6852 - acc: 0.5239Epoch 1/20\n",
            "32/32 [==============================] - 982s 31s/step - loss: 0.6746 - acc: 0.5117\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.51172, saving model to Breast.h5\n",
            "32/32 [==============================] - 1849s 58s/step - loss: 0.6858 - acc: 0.5171 - val_loss: 0.6746 - val_acc: 0.5117\n",
            "Epoch 2/20\n",
            "31/32 [============================>.] - ETA: 19s - loss: 0.6658 - acc: 0.5595Epoch 1/20\n",
            "32/32 [==============================] - 561s 18s/step - loss: 0.6638 - acc: 0.6562\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.51172 to 0.65625, saving model to Breast.h5\n",
            "32/32 [==============================] - 1181s 37s/step - loss: 0.6650 - acc: 0.5664 - val_loss: 0.6638 - val_acc: 0.6562\n",
            "Epoch 3/20\n",
            "31/32 [============================>.] - ETA: 18s - loss: 0.6530 - acc: 0.6764Epoch 1/20\n",
            "32/32 [==============================] - 550s 17s/step - loss: 0.6088 - acc: 0.7178\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.65625 to 0.71777, saving model to Breast.h5\n",
            "32/32 [==============================] - 1166s 36s/step - loss: 0.6509 - acc: 0.6768 - val_loss: 0.6088 - val_acc: 0.7178\n",
            "Epoch 4/20\n",
            "31/32 [============================>.] - ETA: 18s - loss: 0.5987 - acc: 0.6996Epoch 1/20\n",
            "32/32 [==============================] - 554s 17s/step - loss: 0.5819 - acc: 0.7354\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.71777 to 0.73535, saving model to Breast.h5\n",
            "32/32 [==============================] - 1146s 36s/step - loss: 0.6006 - acc: 0.6982 - val_loss: 0.5819 - val_acc: 0.7354\n",
            "Epoch 5/20\n",
            "31/32 [============================>.] - ETA: 19s - loss: 0.6029 - acc: 0.6956Epoch 1/20\n",
            "32/32 [==============================] - 544s 17s/step - loss: 0.5665 - acc: 0.7324\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73535\n",
            "32/32 [==============================] - 1180s 37s/step - loss: 0.6027 - acc: 0.6934 - val_loss: 0.5665 - val_acc: 0.7324\n",
            "Epoch 6/20\n",
            "31/32 [============================>.] - ETA: 18s - loss: 0.5893 - acc: 0.6905Epoch 1/20\n",
            "32/32 [==============================] - 552s 17s/step - loss: 0.5598 - acc: 0.7441\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.73535 to 0.74414, saving model to Breast.h5\n",
            "32/32 [==============================] - 1167s 36s/step - loss: 0.5873 - acc: 0.6914 - val_loss: 0.5598 - val_acc: 0.7441\n",
            "Epoch 7/20\n",
            "31/32 [============================>.] - ETA: 17s - loss: 0.5677 - acc: 0.7046Epoch 1/20\n",
            "32/32 [==============================] - 549s 17s/step - loss: 0.5597 - acc: 0.7324\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.74414\n",
            "32/32 [==============================] - 1128s 35s/step - loss: 0.5673 - acc: 0.7051 - val_loss: 0.5597 - val_acc: 0.7324\n",
            "Epoch 8/20\n",
            "31/32 [============================>.] - ETA: 12s - loss: 0.5737 - acc: 0.7077Epoch 1/20\n",
            "32/32 [==============================] - 539s 17s/step - loss: 0.5539 - acc: 0.7383\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.74414\n",
            "32/32 [==============================] - 944s 29s/step - loss: 0.5763 - acc: 0.7061 - val_loss: 0.5539 - val_acc: 0.7383\n",
            "Epoch 9/20\n",
            "31/32 [============================>.] - ETA: 9s - loss: 0.5860 - acc: 0.6925 Epoch 1/20\n",
            "32/32 [==============================] - 542s 17s/step - loss: 0.5551 - acc: 0.7314\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.74414\n",
            "32/32 [==============================] - 846s 26s/step - loss: 0.5889 - acc: 0.6904 - val_loss: 0.5551 - val_acc: 0.7314\n",
            "Epoch 10/20\n",
            "31/32 [============================>.] - ETA: 9s - loss: 0.5620 - acc: 0.7268 Epoch 1/20\n",
            "32/32 [==============================] - 539s 17s/step - loss: 0.5562 - acc: 0.7402\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.74414\n",
            "32/32 [==============================] - 846s 26s/step - loss: 0.5630 - acc: 0.7266 - val_loss: 0.5562 - val_acc: 0.7402\n",
            "Epoch 11/20\n",
            "31/32 [============================>.] - ETA: 9s - loss: 0.5552 - acc: 0.7258 Epoch 1/20\n",
            "32/32 [==============================] - 536s 17s/step - loss: 0.5567 - acc: 0.7363\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.74414\n",
            "32/32 [==============================] - 847s 26s/step - loss: 0.5518 - acc: 0.7285 - val_loss: 0.5567 - val_acc: 0.7363\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2P1CM9uwfhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Model/Breast.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU5qzgNg1jfe",
        "colab_type": "code",
        "outputId": "b5d891d1-91bb-4cbe-8d46-e85d62bd0b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import math\n",
        "#from google.colab.patches import cv2_imshow\n",
        "\n",
        "CATEGORIES = [\"cancer\", \"normal\"]\n",
        "\n",
        "\n",
        "def prepare(filepath):\n",
        "    #IMG_SIZE = 220 # 50 in txt-based\n",
        "    img_array = cv2.imread(filepath)\n",
        "    new_array = cv2.resize(img_array, (227,227))\n",
        "\n",
        "    return new_array.reshape(-1, 227,227, 1)\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/drive/My Drive/Model/Breast.h5\")\n",
        "\n",
        "prediction = model.predict([prepare('/content/drive/My Drive/PNG/cancer/cancer_02-C_0080_1.RIGHT_MLO.LJPEG.1.png')])\n",
        "pred_percent = math.floor(prediction[0][0]*100)\n",
        "print(pred_percent,\"%\")\n",
        "print(prediction)  # will be a list in a list.\n",
        "print(CATEGORIES[int(prediction[0][0])])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 %\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH-M6nUM9RA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal = 2342\n",
        "cancer = 2367\n",
        "\n",
        "if(prediction[0][0]>prediction[0][1]):\n",
        "  result = prediction[0][0]\n",
        "else:\n",
        "  result = prediction[0][1]\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7H_nYYFFoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pixel values rescaling from [0, 255] to [0, 1] interval\n",
        "datagen1 = ImageDataGenerator(rescale=1. / 255)\n",
        "batch_size = 32\n",
        "train_data_dir1 = '/content/drive/My Drive/dataset1/' \n",
        "# Retrieve images and their classes for train and validation sets\n",
        "train_generator1 = datagen1.flow_from_directory(\n",
        "        train_data_dir1,\n",
        "        target_size=(224, 224),\n",
        "        shuffle = True,\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='binary',\n",
        "        subset = 'training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSmIDauXFK6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "image_list = []\n",
        "i = 0\n",
        "for filename in glob.glob('/content/drive/My Drive/dataset/NORMAL/*.jpg'): #assuming jpg\n",
        "    im=filename\n",
        "    image_list.append(im)\n",
        "    #print(i)\n",
        "    i +=1\n",
        "len(image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvxQKWMVLVpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "j=0\n",
        "for i in range(len(image_list)):\n",
        "  temp = image_list[i]\n",
        "  im = Image.open(temp)\n",
        "  temp = temp.replace(\"jpg\", \"png\")\n",
        "  temp = temp.replace(\"/content/drive/My Drive/dataset/NORMAL/\", \"\")\n",
        "  temp = \"/content/drive/My Drive/PNG/normal/\"+temp\n",
        "  im.save(temp)\n",
        "  print(j)\n",
        "  j=j+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxyRRtu6DqBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoX_I6BZXSPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = image_list[0]\n",
        "temp = temp.replace(\"jpg\", \"png\")\n",
        "temp = temp.replace(\"/content/drive/My Drive/dataset/CANCER/\", \"\")\n",
        "temp = \"/content/drive/My Drive/PNG/cancer/\"+temp\n",
        "temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZHR8JJ2ZPKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}